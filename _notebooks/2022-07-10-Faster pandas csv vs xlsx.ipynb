{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster pandas - csv vs. xlsx\n",
    "> \"Which file format is better to use when trying to minimize file size and improve loading times?\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Jaco Verster\n",
    "- categories: [pandas, optimization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example use case\n",
    "\n",
    "A user can upload either **csv** or an **xlsx** log files through a front-end portal. The log files have an average size of around 50MB. The files are uploaded to a cloud storage instance and a Python back-end downloads and process them. The goals are to **minimize cloud storage usage** and to **load the files as fast as possible**.\n",
    "\n",
    "Question: Which file format is better to use, csv or xlsx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: TL;DR compressed csv files use **31% less space** and load **97% faster** than xlsx files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dummy data\n",
    "\n",
    "Generate some dummy data that is roughly 50MB in size and store it in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(10000, 250))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the data as csv and xlsx files to local storage and compress them to further reduce file size. We use the \"zip\" format as it offers the best overall compression ratio vs. read/write speeds. We note that pd.to_excel() takes significantly longer than pd.to_csv()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: csv.csv (deflated 54%)\n"
     ]
    }
   ],
   "source": [
    "# hide-output\n",
    "df.to_csv(\"csv.csv\")\n",
    "! zip csv.zip csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: excel.xlsx (deflated 0%)\n"
     ]
    }
   ],
   "source": [
    "# hide-output\n",
    "df.to_excel(\"excel.xlsx\")\n",
    "! zip excel.zip excel.xlsx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: A quick benchmark of different compression methods native to Pandas is available at the end of the post."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip: if Pandas has errors when reading/writing excel files try installing the openpyxl engine with \"pip install openpyxl\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File size\n",
    "\n",
    "Now, lets consider the files sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jverster jverster 47M Jul  7 16:07 csv.csv\n",
      "-rw-r--r-- 1 jverster jverster 22M Jul  7 16:07 csv.zip\n",
      "-rw-r--r-- 1 jverster jverster 32M Jul  7 16:07 excel.xlsx\n",
      "-rw-r--r-- 1 jverster jverster 32M Jul  7 16:07 excel.zip\n"
     ]
    }
   ],
   "source": [
    "! ls -lh *.{csv,xlsx,zip}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file saves to 47MB and can be compressed at a ratio of 0.47 to 22MB which leads to a space saving of roughly 53%. On the other hand, the xlsx file saves to 32MB, but offers almost no compression gains. The compressed csv.zip file is the smallest option and **31%** smaller than the xlsx file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read speed\n",
    "Next, lets consider the read speed of csv.csv and csv.zip compared to the excel.xlsx file.\n",
    "\n",
    "Pandas can read compressed files directly with pd.read_csv(), but not with pd.read_excel(). We read only the xlsx file convenience sake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv.csv read in:\n",
      "392 ms ± 13.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "csv.zip read in:\n",
      "571 ms ± 16.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "excel.xlsx read in:\n",
      "18.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "print(\"csv.csv read in:\")\n",
    "%timeit pd.read_csv(\"csv.csv\")\n",
    "\n",
    "print(\"csv.zip read in:\")\n",
    "%timeit pd.read_csv(\"csv.zip\")\n",
    "\n",
    "print(\"excel.xlsx read in:\")\n",
    "%timeit -r 1 -n 1 pd.read_excel(\"excel.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a slight reduction in speed when reading the csv.csv compared to csv.zip. Surprisingly, the excel.xlsx file takes 18.1 seconds to read. This means the csv.zip file reads about **97%** faster than the excel.xlsx file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading directly from the cloud\n",
    "\n",
    "Finally, Pandas read_csv() can also read files directly from a url which is useful for this use case.\n",
    "\n",
    "I was interested to test this so I uploaded the csv files to Google Drive and read them directly from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv.csv read from Google Drive in:\n",
      "894 ms ± 67.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "csv.zip read from Google Drive in:\n",
      "927 ms ± 49.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "csv_file_url = \"https://drive.google.com/file/d/1KoserTnHwB14dXHjRMl3PhKnm3fulR3E/view?usp=sharing\"\n",
    "csv_zip_url = \"https://drive.google.com/file/d/1qQjmg9aeVh28y5zSBxaTX-ZBi8JePoFn/view?usp=sharing\"\n",
    "\n",
    "print(\"csv.csv read from Google Drive in:\")\n",
    "%timeit pd.read_csv(csv_file_url)\n",
    "\n",
    "print(\"csv.zip read from Google Drive in:\")\n",
    "%timeit pd.read_csv(csv_zip_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The times are really close. The smaller zip file downloads faster, but then reads slightly slower. With a blazing fast internet connection the csv.zip files might be slightly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "So in summary, compressed csv.zip files will allow us to use **53% less space** and is **97% faster** when compared to excel.xlsx files\n",
    "\n",
    "Very nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of different compression formats\n",
    "\n",
    "Pandas offers \"on-the-fly compression of the output data\" as part of to_csv() and according the the latest documentation it supports the following extensions: \".gzip\", \".bz2\", \".zip\" and \".xz\". A quick experiment is in order, so we export a file in each format, then check file sizes and finally time reading them back in.\n",
    "\n",
    "Note: I did not consider different compression levels, but you can also set this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved csv in 2.59 seconds.\n",
      "Saved gz in 6.94 seconds.\n",
      "Saved bz2 in 5.67 seconds.\n",
      "Saved zip in 5.3 seconds.\n",
      "Saved xz in 54.73 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "compression_formats = [\"csv\", \"gz\", \"bz2\", \"zip\", \"xz\"]\n",
    "\n",
    "for fmt in compression_formats:\n",
    "    t1 = time.perf_counter()\n",
    "    df.to_csv(f\"csv.{fmt}\", compression=\"infer\")\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"Saved {fmt} in {round(t2-t1, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jverster jverster 19M Jul  8 11:09 csv.bz2\n",
      "-rw-r--r-- 1 jverster jverster 47M Jul  8 11:09 csv.csv\n",
      "-rw-r--r-- 1 jverster jverster 22M Jul  8 11:09 csv.gz\n",
      "-rw-r--r-- 1 jverster jverster 21M Jul  8 11:10 csv.xz\n",
      "-rw-r--r-- 1 jverster jverster 22M Jul  8 11:09 csv.zip\n"
     ]
    }
   ],
   "source": [
    "! ls -lh *.{csv,gz,bz2,zip,xz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read csv in 0.47 seconds.\n",
      "Read gz in 0.73 seconds.\n",
      "Read bz2 in 2.46 seconds.\n",
      "Read zip in 0.68 seconds.\n",
      "Read xz in 1.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "for fmt in compression_formats:\n",
    "    t1 = time.perf_counter()\n",
    "    pd.read_csv(f\"csv.{fmt}\")\n",
    "    t2 = time.perf_counter()\n",
    "    print(f\"Read {fmt} in {round(t2-t1, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Best save times:\n",
    "1. zip\n",
    "2. bz2\n",
    "3. gz\n",
    "\n",
    "Best compression rates (all close):\n",
    "1. bz2\n",
    "2. xz\n",
    "3. zip and gz\n",
    "\n",
    "Best load times:\n",
    "1. zip\n",
    "2. gz\n",
    "3. xz\n",
    "\n",
    "\n",
    "Best overall:\n",
    "1. \"zip\" has decent compression and good overall save/load times.\n",
    "2. \"gz\" offers decent compression but it is slower when saving.\n",
    "3. \"bz2\" has the best compression but is slow to load."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2cb78e02b6e66c5e4f67839fd4978e58d3144e1bb76b1187588b6a599b727db7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
