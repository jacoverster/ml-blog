<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://jacoverster.github.io/ml-blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jacoverster.github.io/ml-blog/" rel="alternate" type="text/html" /><updated>2022-08-26T02:06:06-05:00</updated><id>https://jacoverster.github.io/ml-blog/feed.xml</id><title type="html">Jaco Verster</title><subtitle>A space to document adventures on my computer.</subtitle><entry><title type="html">My Python development template in 2022</title><link href="https://jacoverster.github.io/ml-blog/python/docker/devcontainer/2022/08/06/Python-development-template.html" rel="alternate" type="text/html" title="My Python development template in 2022" /><published>2022-08-06T00:00:00-05:00</published><updated>2022-08-06T00:00:00-05:00</updated><id>https://jacoverster.github.io/ml-blog/python/docker/devcontainer/2022/08/06/Python-development-template</id><author><name>Jaco Verster</name></author><category term="Python" /><category term="Docker" /><category term="devcontainer" /><summary type="html"><![CDATA[I wish I had this when I started coding! A template for containerized Python development with packaging, CI/CD, code formatting, testing and more.]]></summary></entry><entry><title type="html">Faster pandas - compression format comparison</title><link href="https://jacoverster.github.io/ml-blog/pandas/optimization/2022/07/21/Faster-pandas-compression-formats.html" rel="alternate" type="text/html" title="Faster pandas - compression format comparison" /><published>2022-07-21T00:00:00-05:00</published><updated>2022-07-21T00:00:00-05:00</updated><id>https://jacoverster.github.io/ml-blog/pandas/optimization/2022/07/21/Faster-pandas-compression-formats</id><author><name>Jaco Verster</name></author><category term="pandas" /><category term="optimization" /><summary type="html"><![CDATA[A quick experiment with Pandas' built-in compression formats.]]></summary></entry><entry><title type="html">Faster pandas - csv vs. xlsx</title><link href="https://jacoverster.github.io/ml-blog/pandas/optimization/2022/07/10/Faster-pandas-csv-vs-xlsx.html" rel="alternate" type="text/html" title="Faster pandas - csv vs. xlsx" /><published>2022-07-10T00:00:00-05:00</published><updated>2022-07-10T00:00:00-05:00</updated><id>https://jacoverster.github.io/ml-blog/pandas/optimization/2022/07/10/Faster-pandas-csv-vs-xlsx</id><author><name>Jaco Verster</name></author><category term="pandas" /><category term="optimization" /><summary type="html"><![CDATA[Which file format is better to use when trying to minimize file size and improve loading times?]]></summary></entry><entry><title type="html">Faster Python - tips and examples</title><link href="https://jacoverster.github.io/ml-blog/python/optimization/2022/07/05/Faster-Python.html" rel="alternate" type="text/html" title="Faster Python - tips and examples" /><published>2022-07-05T00:00:00-05:00</published><updated>2022-07-05T00:00:00-05:00</updated><id>https://jacoverster.github.io/ml-blog/python/optimization/2022/07/05/Faster-Python</id><author><name>Jaco Verster</name></author><category term="python" /><category term="optimization" /><summary type="html"><![CDATA[A collection of tips and tricks to speed up your Python code.]]></summary></entry><entry><title type="html">Training a pistol detector with YOLOv5 and Neuralmagic</title><link href="https://jacoverster.github.io/ml-blog/object%20detection/yolov5/neuralmagic/2022/06/30/Neuralmagic-YOLOv5.html" rel="alternate" type="text/html" title="Training a pistol detector with YOLOv5 and Neuralmagic" /><published>2022-06-30T00:00:00-05:00</published><updated>2022-06-30T00:00:00-05:00</updated><id>https://jacoverster.github.io/ml-blog/object%20detection/yolov5/neuralmagic/2022/06/30/Neuralmagic-YOLOv5</id><author><name>Jaco Verster</name></author><category term="object detection" /><category term="yolov5" /><category term="neuralmagic" /><summary type="html"><![CDATA[An pistol detection model trained with Neuralmagic and deployed using DeepSparse, a sparsity-aware inference engine that allows improved model inference performance on CPU hardware.]]></summary></entry></feed>